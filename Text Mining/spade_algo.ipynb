{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "yelp_reviews =pd.read_table('yelp_reviews.txt', header=None)\n",
    "yelp_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup = 0.01\n",
    "min_sup = int(yelp_reviews.shape[0]*sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list\n",
    "yelp_review_list = yelp_reviews[0].map(lambda yelp_review: yelp_review.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = defaultdict(list)\n",
    "\n",
    "for sid, reviews in enumerate(yelp_review_list):\n",
    "    for eid, review in enumerate(reviews):\n",
    "        db[review].append([sid,eid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length 1 itemset\n",
    "\n",
    "db1 = defaultdict(pd.DataFrame)\n",
    "for key, items in db.items():\n",
    "    # compute support of items\n",
    "    support = len(np.unique(list(zip(*items))[0]))\n",
    "    if support >= min_sup:\n",
    "        db1[key] = pd.concat([db1[key], pd.DataFrame(items, columns=['sid','eid' ])], axis=1).set_index('sid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('patterns.txt', 'w') as file:\n",
    "    for key, value in db1.items():\n",
    "        support = len(np.unique(value.index))\n",
    "        file.write(str(support)+\":\"+str(key)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to calculate adj items\n",
    "\n",
    "def close(data, column1, column2):\n",
    "    diff = np.absolute(data[column1]-data[column2])\n",
    "    cond1 = diff<2\n",
    "    cond2 = diff>0\n",
    "    return data[cond1 & cond2]\n",
    "\n",
    "# Length 2 itemset\n",
    "\n",
    "db2 = defaultdict(pd.DataFrame)\n",
    "db1copy = db1.copy()\n",
    "\n",
    "for key1, items1 in db1.items():\n",
    "    for key2, items2 in db1copy.items():\n",
    "\n",
    "        # merge based on key sid\n",
    "        temp = items1.merge(items2, left_index=True, right_index=True, how='inner', suffixes=('_x', '_y'))\n",
    "\n",
    "        # all rows smaller than minimum\n",
    "        if temp.shape[0]<min_sup:\n",
    "            pass\n",
    "\n",
    "        # see if contigious\n",
    "        temp = close(temp, 'eid_x', 'eid_y')\n",
    "\n",
    "        # support check\n",
    "        support = len(np.unique(temp.index))\n",
    "        if support>= min_sup:\n",
    "            db2[key1+\";\"+key2] = temp\n",
    "\n",
    "    # remove key from copy db\n",
    "    db1copy.pop(key1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide length 2\n",
    "db2split = defaultdict()\n",
    "for key, items in db2.items():\n",
    "\n",
    "    # items where first key comes first\n",
    "    idx = items['eid_x']<items['eid_y']\n",
    "    # case when x comes first\n",
    "    support = len(np.unique(items[idx].index))\n",
    "    if support >= min_sup:\n",
    "        db2split[key] = items[idx]\n",
    "\n",
    "    # case when y comes first\n",
    "    support = len(np.unique(items[~idx].index))\n",
    "    if support>= min_sup:\n",
    "        keys = key.split(';')\n",
    "        items.columns = ['eid_y', 'eid_x']\n",
    "        db2split[keys[1]+';'+keys[0]] = items[~idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length 3 itemsets\n",
    "\n",
    "db3 = defaultdict(pd.DataFrame)\n",
    "\n",
    "for key1, items1 in db2split.items():\n",
    "    for key2, items2 in db2split.items():\n",
    "        # compare key1 first and key2 last\n",
    "        key1last = key1.split(';')[1]\n",
    "        key2first = key2.split(';')[0]\n",
    "        key2last = key2.split(';')[1]\n",
    "\n",
    "        # combine if keys are same\n",
    "        if key1last==key2first:\n",
    "            temp = items1.merge(items2, left_index=True, right_index=True, how='inner')\n",
    "            # minimum support check\n",
    "            support = len(np.unique(temp.index))\n",
    "            if temp.shape[0] >=min_sup:\n",
    "                db3[key1+\" \"+key2last] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = db1.copy()\n",
    "results.update(db2split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"patterns.txt\", 'w') as file:\n",
    "    # length 1\n",
    "    for key, items in results.items():\n",
    "        support = len(np.unique(items.index))\n",
    "        file.write(str(support)+\":\"+';'.join(key.split())+ '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
